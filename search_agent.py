"""SearchAgent sub-agent for systematic web research using code execution.

This module provides a research agent that generates and executes complete
Python programs to conduct research, replacing the multi-step tool calling
pattern with a single code generation and execution approach.

Current mode: LLM generates complete code -> execute_search_code() -> results
Previous mode: LLM decision -> tool1 -> LLM decision -> tool2 -> ... (multiple cycles)
"""

from deepagents import SubAgent
from code_executor import create_execute_search_code_tool
from tools import get_current_time, get_collected_summary


# Default maximum search rounds
DEFAULT_MAX_SEARCH_ROUNDS = 5


SEARCH_AGENT = SubAgent(
    name="search_agent",
    description=f"""ä¸“ä¸šçš„ç ”ç©¶ä»£ç†ï¼Œé€šè¿‡ç”Ÿæˆå¹¶æ‰§è¡Œå®Œæ•´çš„Pythonæœç´¢ç¨‹åºæ¥å®Œæˆç ”ç©¶ä»»åŠ¡ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
- ğŸ–¥ï¸ ä»£ç æ‰§è¡Œæ¨¡å¼ï¼šç”Ÿæˆå®Œæ•´çš„Pythonç¨‹åºï¼Œä¸€æ¬¡æ€§æ‰§è¡Œæ‰€æœ‰æœç´¢é€»è¾‘
- ğŸ” LLMæ™ºèƒ½é‡æ’ï¼šæ‰©å¤§å¬å›50æ¡ï¼Œä½¿ç”¨LLMç­›é€‰æœ€ä¼˜10æ¡
- ğŸ• å¼ºæ—¶æ•ˆæ€§ï¼šé»˜è®¤åªæœç´¢æœ€è¿‘ä¸€ä¸ªæœˆå†…çš„ä¿¡æ¯ï¼Œæ‹’ç»è¿‡æ—¶å†…å®¹
- ğŸ“Š ç»“æ„åŒ–è¾“å‡ºï¼šç”Ÿæˆå¸¦æ—¶é—´æ ‡æ³¨çš„ç ”ç©¶æŠ¥å‘Š
- ğŸ”„ åŠ¨æ€è°ƒæ•´ï¼šç¨‹åºå†…è‡ªä¸»å†³å®šæœç´¢ç­–ç•¥å’Œå¾ªç¯æ§åˆ¶
- ğŸ¤– è‡ªä¸»åæ€ï¼šä»£ç ä¸­åŒ…å«å®Œæ•´çš„åæ€å’Œå†³ç­–é€»è¾‘

é€‚ç”¨åœºæ™¯ï¼š
- éœ€è¦æœ€æ–°ä¿¡æ¯çš„ç ”ç©¶ä»»åŠ¡ï¼ˆæ–°é—»ã€å¸‚åœºåŠ¨æ€ã€æŠ€æœ¯è¿›å±•ï¼‰
- éœ€è¦ä»å¤šä¸ªè§’åº¦æœç´¢åŒä¸€ä¸»é¢˜
- éœ€è¦å¯¹æ¯”å¤šä¸ªæ¥æºçš„ä¿¡æ¯å¹¶è¿›è¡Œæ—¶æ•ˆæ€§éªŒè¯
- å¤æ‚ç ”ç©¶ä»»åŠ¡ï¼Œéœ€è¦å¤šè½®è¿­ä»£æœç´¢""",

    system_prompt=f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ï¼Œé€šè¿‡ç”Ÿæˆå®Œæ•´çš„Pythonç¨‹åºæ¥å®Œæˆæœç´¢ä»»åŠ¡ã€‚

## ğŸ–¥ï¸ å·¥ä½œæ¨¡å¼

ä½ éœ€è¦ç”Ÿæˆä¸€æ®µå®Œæ•´çš„Pythonç¨‹åºä»£ç ï¼Œç„¶åè°ƒç”¨ `execute_search_code` å·¥å…·æ¥æ‰§è¡Œå®ƒã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ‰€æœ‰æœç´¢é€»è¾‘å†™å…¥ä¸€æ®µç¨‹åºï¼Œä¸€æ¬¡æ€§æ‰§è¡Œå®Œæˆï¼Œè€Œä¸æ˜¯å¤šæ¬¡è°ƒç”¨å·¥å…·ã€‚

---

## ğŸ”ã€æ¨èã€‘ä½¿ç”¨LLMæ™ºèƒ½é‡æ’

ä¸ºäº†è·å¾—æ›´é«˜è´¨é‡çš„æœç´¢ç»“æœï¼Œ**å¼ºçƒˆæ¨èä½¿ç”¨ `web_search_with_rerank`**ï¼š

```python
# æ¨èï¼šä½¿ç”¨æ™ºèƒ½é‡æ’æœç´¢ï¼ˆå¬å›50æ¡ â†’ LLMç­›é€‰æœ€ä¼˜10æ¡ï¼‰
search_result = web_search_with_rerank(
    query="æœç´¢å…³é”®è¯",
    task_description="å…·ä½“çš„ç ”ç©¶ä»»åŠ¡æè¿°",
    max_results=50,       # å¬å›50æ¡
    top_k=10,             # LLMç­›é€‰å‡ºæœ€ä¼˜10æ¡
    freshness="oneMonth"
)

# search_result['results'] æ˜¯ç»è¿‡LLMé‡æ’åçš„æœ€ä¼˜ç»“æœ
for item in search_result['results']:
    print(f"[{{item['llm_score']}}åˆ†] {{item['title']}}")
    print(f"  é€‰ä¸­ç†ç”±: {{item['llm_reason']}}")
    print(f"  æ¥æº: {{item['domain']}} ({{'æƒå¨' if item['is_authoritative'] else 'æ™®é€š'}})")
```

### é‡æ’è¯„ä¼°ç»´åº¦

LLMä¼šæ ¹æ®ä»¥ä¸‹ç»´åº¦ç»¼åˆè¯„åˆ†ï¼š
1. **ä¿¡æ¯ä»·å€¼ (40%)**ï¼šä¸ä»»åŠ¡çš„ç›¸å…³æ€§ï¼Œæ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
2. **æ—¶æ•ˆæ€§ (30%)**ï¼šå‘å¸ƒæ—¶é—´æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼Œè¶Šæ–°é²œè¶Šå¥½
3. **å†…å®¹è´¨é‡ (20%)**ï¼šä¿¡æ¯æ˜¯å¦è¯¦å®ã€å…·ä½“ã€æœ‰æ·±åº¦
4. **æ¥æºæƒå¨æ€§ (10%)**ï¼šç½‘ç«™åœ¨è¯¥é¢†åŸŸæ˜¯å¦æƒå¨

---

## â°ã€é¦–è¦åŸåˆ™ã€‘æ—¶é—´æ„ŸçŸ¥

ç¨‹åºå¿…é¡»é¦–å…ˆè·å–å½“å‰æ—¶é—´ï¼Œæ‰€æœ‰åç»­å†³ç­–éƒ½åŸºäºæ­¤ï¼š

```python
# ç¬¬ä¸€æ­¥ï¼šè·å–å½“å‰æ—¶é—´
t = get_current_time()
print(f"æœç´¢å¼€å§‹: {{t['message']}}")
print(f"ä»Šå¤©æ˜¯ {{t['date']}} {{t['weekday']}}")
```

---

## ğŸ“ ç¨‹åºæ¨¡æ¿ï¼ˆæ¨èä½¿ç”¨é‡æ’ï¼‰

ä»¥ä¸‹æ˜¯æ ‡å‡†çš„æœç´¢ç¨‹åºæ¨¡æ¿ï¼Œä½¿ç”¨LLMæ™ºèƒ½é‡æ’æå‡è´¨é‡ï¼š

```python
# ============================================
# ç¬¬1æ­¥ï¼šè·å–å½“å‰æ—¶é—´ï¼ˆå¿…é¡»é¦–å…ˆæ‰§è¡Œï¼‰
# ============================================
t = get_current_time()
print(f"æœç´¢å¼€å§‹: {{t['message']}}")

# ============================================
# ç¬¬2æ­¥ï¼šåˆå§‹åŒ–æœç´¢ä¼šè¯
# ============================================
init_search_session(max_search_rounds=5)
set_search_task(
    task="[å…·ä½“çš„ç ”ç©¶ä»»åŠ¡æè¿°]",
    required_info_types=["news", "data", "analysis"],  # æ ¹æ®ä»»åŠ¡è°ƒæ•´
    min_sources=3,
    time_sensitivity="oneMonth"
)

# ============================================
# ç¬¬3æ­¥ï¼šä½¿ç”¨æ™ºèƒ½é‡æ’æœç´¢ï¼ˆæ¨èï¼‰
# ============================================
print("\\n=== æ‰§è¡Œæ™ºèƒ½æœç´¢ ===")

# ä½¿ç”¨ web_search_with_rerankï¼šå¬å›50æ¡ â†’ LLMç­›é€‰æœ€ä¼˜10æ¡
search_result = web_search_with_rerank(
    query="[æœç´¢å…³é”®è¯]",
    task_description="[å…·ä½“çš„ç ”ç©¶ä»»åŠ¡æè¿°]",
    max_results=50,       # æ‰©å¤§å¬å›èŒƒå›´
    top_k=10,             # LLMç­›é€‰æœ€ä¼˜ç»“æœ
    freshness="oneMonth"
)

print(f"æœç´¢åˆ° {{search_result['total_found']}} æ¡ç»“æœ")
print(f"é‡æ’æ‘˜è¦: {{search_result['rerank_summary']}}")
print(f"è¿”å›æœ€ä¼˜ {{search_result['total_returned']}} æ¡\\n")

# å¤„ç†é‡æ’åçš„ç»“æœ
for item in search_result['results']:
    title = item['title']
    url = item['url']
    score = item.get('llm_score', 0)
    reason = item.get('llm_reason', '')
    is_auth = item.get('is_authoritative', False)

    print(f"[{{score}}åˆ†] {{title}}")
    print(f"  ç†ç”±: {{reason}}")
    print(f"  æ¥æº: {{item['domain']}} {{'â˜…æƒå¨' if is_auth else ''}}")

    # è¯»å–ç½‘é¡µè¯¦ç»†å†…å®¹
    try:
        page_data = web_read(url)
        main_content = page_data.get('content', item.get('snippet', ''))
        publish_time = page_data.get('publish_time')

        print(f"  å‘å¸ƒæ—¶é—´: {{publish_time or 'æœªçŸ¥'}}")
        print(f"  å†…å®¹é•¿åº¦: {{len(main_content)}} å­—ç¬¦")
    except Exception as e:
        main_content = item.get('snippet', '')
        publish_time = item.get('publish_time')
        print(f"  è¯»å–å¤±è´¥: {{str(e)[:50]}}")

    # æ”¶é›†æœ‰ä»·å€¼çš„ä¿¡æ¯
    add_collected_info(
        content=main_content,
        source=url,
        publish_time=publish_time,
        relevance=score / 100,  # è½¬æ¢ä¸º0-1èŒƒå›´
        category="main"
    )
    print()

# è®°å½•æœç´¢
record_search_result(
    query="[æœç´¢å…³é”®è¯]",
    freshness="oneMonth",
    total_results=search_result['total_found'],
    valid_results=search_result['total_returned'],
    notes=search_result['rerank_summary']
)

# ============================================
# ç¬¬4æ­¥ï¼šè¾“å‡ºç»“æœæ‘˜è¦
# ============================================
print("\\n" + "="*50)
print("æœç´¢å®Œæˆï¼")
summary = get_collected_summary()
print(f"æ”¶é›†ä¿¡æ¯: {{summary['total_items']}} æ¡")
print(f"ç‹¬ç«‹æ¥æº: {{summary['unique_sources']}} ä¸ª")
print(f"ä¿¡æ¯ç±»åˆ«: {{summary['categories']}}")

# è®¾ç½®è¿”å›ç»“æœ
result = summary
```

---

## ğŸ› ï¸ å¯ç”¨å‡½æ•°

åœ¨ç”Ÿæˆçš„ä»£ç ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡½æ•°ï¼š

### æ—¶é—´å·¥å…·
- `get_current_time()` - è·å–å½“å‰ç³»ç»Ÿæ—¶é—´ï¼Œè¿”å›datetime, date, yearç­‰

### æœç´¢å·¥å…·ï¼ˆæ¨èä½¿ç”¨é‡æ’ç‰ˆæœ¬ï¼‰
- `web_search_with_rerank(query, task_description, max_results=50, top_k=10, topic, freshness)` - **æ¨è**ï¼šæ™ºèƒ½é‡æ’æœç´¢
- `web_search(query, max_results=5, freshness="noLimit", topic="general")` - æ™®é€šæœç´¢
- `web_read(url)` - è¯»å–ç½‘é¡µå¹¶ä½¿ç”¨LLMæå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¿”å› dict:
  - `title`: ç½‘é¡µæ ‡é¢˜
  - `publish_time`: å‘å¸ƒæ—¶é—´ (YYYY-MM-DD)
  - `content`: ä¸»è¦å†…å®¹æ‘˜è¦
  - `raw_content`: åŸå§‹ç½‘é¡µå†…å®¹
  - `url`: åŸå§‹URL

### LLMé‡æ’å·¥å…·
- `llm_rerank_results(results, task_description, top_k=10, freshness_requirement)` - å¯¹å·²æœ‰ç»“æœè¿›è¡Œé‡æ’

### ä¼šè¯ç®¡ç†
- `init_search_session(max_search_rounds=5)` - åˆå§‹åŒ–æœç´¢ä¼šè¯
- `set_search_task(task, required_info_types, min_sources, time_sensitivity)` - è®¾ç½®ä»»åŠ¡ç›®æ ‡
- `get_search_status()` - è·å–å½“å‰æœç´¢çŠ¶æ€
- `get_search_history()` - è·å–æœç´¢å†å²

### ä¿¡æ¯æ”¶é›†
- `record_search_result(query, freshness, total_results, valid_results, notes)` - è®°å½•æœç´¢ç»“æœ
- `add_collected_info(content, source, publish_time, relevance, category)` - ä¿å­˜æ”¶é›†çš„ä¿¡æ¯
- `get_collected_summary()` - è·å–å·²æ”¶é›†ä¿¡æ¯çš„æ‘˜è¦

### åæ€å·¥å…·
- `reflect_on_coverage(task_description, covered_aspects, missing_aspects)` - è¯„ä¼°è¦†ç›–æƒ…å†µ
- `evaluate_search_quality(dimension)` - è¯„ä¼°è´¨é‡ï¼ˆç»´åº¦ï¼šcompleteness/timeliness/relevance/diversity/credibilityï¼‰
- `should_continue_searching(task_complete, reasons_to_stop)` - å†³å®šæ˜¯å¦ç»§ç»­æœç´¢

### å…¶ä»–
- `print()` - è¾“å‡ºä¿¡æ¯
- `json` - JSONæ¨¡å—
- `re` - æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—ï¼ˆç”¨äºæå–ç½‘é¡µä¸­çš„å‘å¸ƒæ—¶é—´ç­‰ï¼‰

---

## â° æ—¶æ•ˆæ€§è§„åˆ™

åœ¨ä»£ç ä¸­è®¾ç½® `freshness` å‚æ•°æ—¶ï¼Œå¿…é¡»æ ¹æ®ä¿¡æ¯ç±»å‹é€‰æ‹©ï¼š

| ä¿¡æ¯ç±»å‹ | freshness | è¯´æ˜ |
|---------|-----------|------|
| è‚¡ç¥¨è¡Œæƒ…ã€çªå‘æ–°é—» | `"oneDay"` | å®æ—¶æ€§è¦æ±‚æœ€é«˜ |
| æŠ€æœ¯åŠ¨æ€ã€äº§å“å‘å¸ƒ | `"oneWeek"` | ä¸€å‘¨å†…çš„ä¿¡æ¯ |
| è¡Œä¸šåˆ†æã€ç ”ç©¶æŠ¥å‘Š | `"oneMonth"` | **é»˜è®¤é€‰æ‹©** |
| é•¿æœŸè¶‹åŠ¿ã€å†å²å¯¹æ¯” | `"oneYear"` | éœ€è¦å†å²æ•°æ®æ—¶ |
| ç”¨æˆ·æ˜ç¡®è¦æ±‚å†å² | `"noLimit"` | å¿…é¡»æœ‰æ˜ç¡®è¯´æ˜ |

---

## ğŸ“¤ è¾“å‡ºè¦æ±‚

ç”Ÿæˆçš„ä»£ç åº”è¯¥ï¼š

1. **æ¸…æ™°çš„è¿›åº¦è¾“å‡º**ï¼šä½¿ç”¨print()æ˜¾ç¤ºæœç´¢è¿›åº¦
2. **è®¾ç½®resultå˜é‡**ï¼šå°†æœ€ç»ˆç»“æœèµ‹å€¼ç»™resultå˜é‡
3. **å®Œæ•´çš„æœç´¢æŠ¥å‘Š**ï¼šè¾“å‡ºç»“æ„åŒ–çš„æœç´¢ç»“æœ

æœ€ç»ˆè¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
```
æœç´¢å¼€å§‹: 2025å¹´2æœˆ16æ—¥ ...

=== æ‰§è¡Œæ™ºèƒ½æœç´¢ ===
æœç´¢åˆ° 50 æ¡ç»“æœ
é‡æ’æ‘˜è¦: LLMé‡æ’åºå®Œæˆ
è¿”å›æœ€ä¼˜ 10 æ¡

[95åˆ†] æ ‡é¢˜1
  ç†ç”±: æƒå¨æ¥æºï¼Œä¿¡æ¯æœ€æ–°
  æ¥æº: eastmoney.com â˜…æƒå¨
...

æœç´¢å®Œæˆï¼
æ”¶é›†ä¿¡æ¯: 10 æ¡
ç‹¬ç«‹æ¥æº: 8 ä¸ª
```

---

## âš ï¸ é‡è¦æé†’

1. **å¿…é¡»é¦–å…ˆè°ƒç”¨get_current_time()** - è¿™æ˜¯æ—¶é—´æ„ŸçŸ¥çš„åŸºç¡€
2. **æ¨èä½¿ç”¨web_search_with_rerank** - è·å¾—æ›´é«˜è´¨é‡çš„æœç´¢ç»“æœ
3. **è®¾ç½®resultå˜é‡** - ä¾¿äºè¿”å›ç»“æ„åŒ–ç»“æœ
4. **ç¦æ­¢ä½¿ç”¨importè¯­å¥** - æ‰€æœ‰å·¥å…·å·²é¢„ç½®
5. **ç¦æ­¢å®šä¹‰ç±»** - åªä½¿ç”¨å‡½æ•°å¼ç¼–ç¨‹

---

## è°ƒç”¨æ–¹å¼

ç”Ÿæˆä»£ç åï¼Œä½¿ç”¨execute_search_codeå·¥å…·æ‰§è¡Œï¼š

```
execute_search_code(code="ä½ çš„å®Œæ•´ç¨‹åºä»£ç ")
```

å·¥å…·å°†è¿”å›ï¼š
- success: æ˜¯å¦æˆåŠŸæ‰§è¡Œ
- output: æ‰€æœ‰print()è¾“å‡º
- result: resultå˜é‡çš„å€¼
- error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰""",

    tools=[
        create_execute_search_code_tool(),  # æ ¸å¿ƒå·¥å…·ï¼šæ‰§è¡Œç”Ÿæˆçš„ä»£ç 
        get_current_time,                    # è¾…åŠ©å·¥å…·ï¼šç›´æ¥è·å–æ—¶é—´
        get_collected_summary,               # è¾…åŠ©å·¥å…·ï¼šè·å–æ”¶é›†ç»“æœ
    ],
)

__all__ = ["SEARCH_AGENT", "DEFAULT_MAX_SEARCH_ROUNDS"]


def create_search_agent():
    """Create and return a deep agent with search_agent capabilities."""
    import os
    from datetime import datetime
    from deepagents import create_deep_agent
    from langchain_openai import ChatOpenAI

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    model = ChatOpenAI(
        temperature=0.3,
        model="glm-4.7",
        openai_api_key=os.getenv("ZHIPUAI_API_KEY"),
        openai_api_base="https://open.bigmodel.cn/api/paas/v4/"
    )

    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢åŠ©æ‰‹ï¼Œè´Ÿè´£è°ƒç”¨ search_agent å®Œæˆæœç´¢ä»»åŠ¡ã€‚

## â° å½“å‰ç³»ç»Ÿæ—¶é—´

**ç°åœ¨çš„æ—¶é—´æ˜¯: {current_time}**

---

## æ ¸å¿ƒä»»åŠ¡

å½“ç”¨æˆ·æä¾›æœç´¢æŸ¥è¯¢æ—¶ï¼Œè°ƒç”¨ search_agent æ‰§è¡Œæœç´¢ä»»åŠ¡ã€‚
search_agent ä¼šç”Ÿæˆå¹¶æ‰§è¡Œå®Œæ•´çš„ Python æœç´¢ç¨‹åºæ¥å®Œæˆç ”ç©¶ä»»åŠ¡ã€‚

## å·¥ä½œæµç¨‹

1. æ¥æ”¶ç”¨æˆ·çš„æœç´¢æŸ¥è¯¢
2. è°ƒç”¨ search_agentï¼Œæ˜ç¡®å‘ŠçŸ¥æœç´¢ç›®æ ‡å’Œæ—¶æ•ˆæ€§è¦æ±‚
3. ç­‰å¾… search_agent è¿”å›æœç´¢ç»“æœ
4. å‘ç”¨æˆ·å±•ç¤ºæœç´¢ç»“æœ

## æ³¨æ„äº‹é¡¹

- å¯¹äºæ—¶æ•ˆæ€§è¦æ±‚é«˜çš„ä¿¡æ¯ï¼ˆæ–°é—»ã€è‚¡ä»·ï¼‰ï¼Œè¦æ±‚ search_agent ä½¿ç”¨ oneDay æˆ– oneWeek
- å¯¹äºä¸€èˆ¬æ€§ç ”ç©¶ï¼Œä½¿ç”¨ oneMonth
- æ˜ç¡®å‘ŠçŸ¥ search_agent éœ€è¦æœç´¢çš„å†…å®¹å’ŒæœŸæœ›çš„ç»“æœæ•°é‡
"""

    agent = create_deep_agent(
        model=model,
        subagents=[SEARCH_AGENT],
        system_prompt=system_prompt,
        debug=True
    )

    return agent


if __name__ == "__main__":
    import sys

    # Get query from command line arguments
    if len(sys.argv) < 2:
        print("Usage: python search_agent.py <search query>")
        print("Example: python search_agent.py 'AI trends 2025'")
        sys.exit(1)

    query = " ".join(sys.argv[1:])

    # Print search task info
    print("=" * 60)
    print("ğŸ“‹ æœç´¢ä»»åŠ¡")
    print("=" * 60)
    print(f"  æŸ¥è¯¢å†…å®¹: {query}")
    print(f"  æ‰§è¡Œæ¨¡å¼: Agent ä»£ç ç”Ÿæˆ + æ‰§è¡Œ")
    print("=" * 60)
    print()

    # Create agent and execute search
    print("ğŸš€ å¯åŠ¨ Search Agent...\n")

    agent = create_search_agent()

    # Prepare the query for the agent
    agent_query = f"""è¯·æ‰§è¡Œä»¥ä¸‹æœç´¢ä»»åŠ¡ï¼š

æœç´¢æŸ¥è¯¢: {query}

è¦æ±‚ï¼š
1. ä½¿ç”¨ execute_search_code å·¥å…·ç”Ÿæˆå¹¶æ‰§è¡Œæœç´¢ä»£ç 
2. æ—¶æ•ˆæ€§è¦æ±‚: oneMonth (ä¸€ä¸ªæœˆå†…)
3. è¿”å› 5 æ¡ç»“æœ
4. å±•ç¤ºæ¯æ¡ç»“æœçš„æ ‡é¢˜ã€URLã€å‘å¸ƒæ—¶é—´å’Œæ‘˜è¦

è¯·å¼€å§‹æœç´¢å¹¶è¿”å›ç»“æœã€‚
"""

    # Stream the agent execution
    for chunk in agent.stream(
        {"messages": [{"role": "user", "content": agent_query}]},
        stream_mode="updates"
    ):
        for node_name, node_output in chunk.items():
            if node_output is not None and "messages" in node_output:
                messages = node_output["messages"]
                if hasattr(messages, 'value'):
                    messages = messages.value
                for msg in messages:
                    content = getattr(msg, 'content', str(msg))
                    if content:
                        print(f"[{node_name}] {content}")
            elif node_output is not None:
                print(f"[{node_name}] {node_output}")

    print()
    print("=" * 60)
    print("âœ… æœç´¢å®Œæˆ")
    print("=" * 60)
